{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing code for both datasets\n",
    "\n",
    "adapted from [here](https://www.kaggle.com/code/caleones/ml-for-early-detection-of-heart-disease) and [here](https://www.kaggle.com/code/hamza062/heart-disease-prediction-ml-88-accuracy#1.-Import-Libraries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the dataset (also sourced from the two referenced notebooks)\n",
    "This dataset is a reduced version of a larger heart disease prediction dataset \n",
    "id: A unique identifier for each patient.\n",
    "The features are as follows\n",
    "1. age: The patient's age in years. ranging from \n",
    "2. sex: The patient's sex (male or female).\n",
    "3. dataset: The dataset the patient's record came from (e.g., Cleveland). This is not used in our predictive model \n",
    "4. cp: Type of chest pain. This indicates what kind of chest pain the patient presented with \n",
    "5. trestbps: Resting blood pressure. A high resting blood pressure is indicative of hyper tension\n",
    "6. chol: Serum cholesterol in mg/dl. A high cholesterol level \n",
    "7. fbs: Fasting blood sugar > 120 mg/dl. A high fasting blood sugar typically is indicative of diabetes,  which correlates with heart issues\n",
    "8. restecg: Resting electrocardiographic results.\n",
    "9. thalch: Maximum heart rate achieved.\n",
    "10. exang: Exercise induced angina.\n",
    "11. oldpeak: ST depression induced by exercise relative to rest.\n",
    "12. slope: The slope of the peak exercise ST segment.\n",
    "13. ca: Number of major vessels (0-3) colored by flourosopy.\n",
    "14. thal: A thalium stress result.\n",
    "\n",
    " Target : num: The presence of heart disease (the predicted attribute)\n",
    "\n",
    "\n",
    " This dataset has the following missing values for each column:\n",
    "\n",
    " 1. Ca: 611 rows\n",
    " 2. thal : 486 rows\n",
    " 3. Slope : 309 rows\n",
    " 4. TrestBPS : 59 rows\n",
    " 5. restecg: 2 rows\n",
    " 6. thalch: 55 rows\n",
    " 7. Exang: 55 rows \n",
    " 8. OldPeak: 62 rows \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_disease_uci.csv')\n",
    "df_procesed = df.drop(columns=['id'])\n",
    "\n",
    "# apply One-Hot Encoding to categorical columns\n",
    "#df_procesed = pd.get_dummies(df_procesed, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  dataset  cp  trestbps   chol  fbs  restecg  thalch  exang  \\\n",
       "194   68    0        0   2     120.0  211.0  0.0      0.0   115.0    0.0   \n",
       "250   57    1        0   0     110.0  201.0  0.0      1.0   126.0    1.0   \n",
       "636   52    1        2   0      95.0    NaN  NaN      1.0    82.0    1.0   \n",
       "407   49    0        1   2     130.0  207.0  0.0      2.0   135.0    0.0   \n",
       "362   43    0        1   3     100.0  223.0  0.0      1.0   142.0    0.0   \n",
       "\n",
       "     oldpeak  slope   ca  thal  num  \n",
       "194      1.5    1.0  0.0   1.0    0  \n",
       "250      1.5    1.0  0.0   0.0    0  \n",
       "636      NaN    NaN  NaN   NaN    2  \n",
       "407      0.0    NaN  NaN   NaN    0  \n",
       "362      0.0    NaN  NaN   NaN    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_procesed['chol'] = df_procesed['chol'].replace(0, np.nan)\n",
    "num =  ['trestbps', 'chol', 'thalch', 'oldpeak'] # Numerical columns with NANS\n",
    "columns_to_encode = ['sex','dataset', 'cp', 'thal', 'slope', 'exang', 'restecg', 'fbs','ca']\n",
    "categ_cols = ['fbs', 'restecg', 'exang', 'slope', 'thal', 'ca']\n",
    "index = {}\n",
    "label_encoders = {}\n",
    "\n",
    "for colm in columns_to_encode:\n",
    "    nan_ixs = np.where(df_procesed[colm].isna())[0]\n",
    "    index[colm] = nan_ixs\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in columns_to_encode:\n",
    "    \n",
    "    \n",
    "    df_procesed[col] = le.fit_transform(df_procesed[col])\n",
    "    \n",
    "    label_encoders[col] = le\n",
    "    for col1, idxs in index.items():\n",
    "        df_procesed.loc[idxs, col1] = np.nan\n",
    "    \n",
    "\n",
    "df_procesed.sample(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values trestbps : 6.41%\n",
      "MAE for Random Forest Imputation:  12.987896160462476\n",
      "RMSE for Random Forest Imputation:  16.68531235286742\n",
      "R2 Score for Random Forest Imputation:  0.13074643697451305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70088666\\AppData\\Local\\Temp\\ipykernel_23436\\3727254149.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_missing[col] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values chol : 21.96%\n",
      "MAE for Random Forest Imputation:  37.67404300158583\n",
      "RMSE for Random Forest Imputation:  47.5130016143418\n",
      "R2 Score for Random Forest Imputation:  0.0922755480202152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70088666\\AppData\\Local\\Temp\\ipykernel_23436\\3727254149.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_missing[col] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values thalch : 5.98%\n",
      "MAE for Random Forest Imputation:  15.986669522034932\n",
      "RMSE for Random Forest Imputation:  20.155850131510356\n",
      "R2 Score for Random Forest Imputation:  0.43154292977164843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70088666\\AppData\\Local\\Temp\\ipykernel_23436\\3727254149.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_missing[col] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values oldpeak : 6.74%\n",
      "MAE for Random Forest Imputation:  0.5720316398754088\n",
      "RMSE for Random Forest Imputation:  0.7996517380790313\n",
      "R2 Score for Random Forest Imputation:  0.4925453845818921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70088666\\AppData\\Local\\Temp\\ipykernel_23436\\3727254149.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_missing[col] = y_pred\n"
     ]
    }
   ],
   "source": [
    "for col in num:\n",
    "    \n",
    "    df_with_missing = df_procesed[df_procesed[col].isna()]\n",
    "    # dropna removes all rows with missing values\n",
    "    df_without_missing = df_procesed[df_procesed[col].notna()]\n",
    "    \n",
    "    # split the data into X and y and we will only take the columns with no missing values\n",
    "    X = df_without_missing.drop([col], axis=1)\n",
    "    y = df_without_missing[col]\n",
    "    \n",
    "    # split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Random Forest Imputation\n",
    "    rf_model = LGBMRegressor(\n",
    "        objective = \"regression\",\n",
    "        metric = \"rmse\",\n",
    "        n_estimators =  1000,\n",
    "        bagging_freq = 1,subsample = 0.413103572972995, \n",
    "                             colsample_bytree = 0.5816717344110182,\n",
    "                             min_data_in_leaf = 20,\n",
    "                             learning_rate = 0.004730072022055302,\n",
    "                             num_leaves = 364, verbose = -1 ,random_state=42)\n",
    "\n",
    "    \n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the model\n",
    "    y_preds = rf_model.predict(X_test)\n",
    "    print(\"Missing Values\", col, \":\", str(round((df_procesed[col].isnull().sum() / len(df_procesed)) * 100, 2))+\"%\")\n",
    "    print(\"MAE for Random Forest Imputation: \", mean_absolute_error(y_test, y_preds))\n",
    "    print(\"RMSE for Random Forest Imputation: \", np.sqrt(mean_squared_error(y_test, y_preds)))\n",
    "    print(\"R2 Score for Random Forest Imputation: \", r2_score(y_test, y_preds))\n",
    "    \n",
    "    y_pred = np.round(rf_model.predict(df_with_missing.drop([col], axis=1)))\n",
    "    \n",
    "    df_with_missing[col] = y_pred\n",
    "    \n",
    "    df_procesed = pd.concat([df_with_missing, df_without_missing], axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>137.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  dataset  cp  trestbps   chol  fbs  restecg  thalch  exang  \\\n",
       "287   58    1        0   1     125.0  220.0  0.0      1.0   144.0    0.0   \n",
       "68    59    1        0   0     170.0  326.0  0.0      0.0   140.0    1.0   \n",
       "849   48    1        3   0     133.0  272.0  0.0      2.0   137.0    NaN   \n",
       "508   47    1        1   0     150.0  226.0  0.0      1.0    98.0    1.0   \n",
       "856   71    1        3   2     137.0  221.0  0.0      1.0   120.0    NaN   \n",
       "\n",
       "     oldpeak  slope   ca  thal  num  \n",
       "287      0.4    1.0  NaN   2.0    0  \n",
       "68       3.4    0.0  0.0   2.0    2  \n",
       "849      0.0    NaN  NaN   NaN    0  \n",
       "508      1.5    1.0  0.0   2.0    1  \n",
       "856      1.0    NaN  NaN   NaN    3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_procesed.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature 'fbs' has been imputed with 80.12 accuracy\n",
      "\n",
      "The feature 'restecg' has been imputed with 65.22 accuracy\n",
      "\n",
      "The feature 'exang' has been imputed with 79.19 accuracy\n",
      "\n",
      "The feature 'slope' has been imputed with 69.11 accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70088666\\AppData\\Local\\Temp\\ipykernel_23436\\4010348627.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_missing[col] = y_pred\n",
      "C:\\Users\\P70088666\\AppData\\Local\\Temp\\ipykernel_23436\\4010348627.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_missing[col] = y_pred\n",
      "C:\\Users\\P70088666\\AppData\\Local\\Temp\\ipykernel_23436\\4010348627.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_missing[col] = y_pred\n",
      "C:\\Users\\P70088666\\AppData\\Local\\Temp\\ipykernel_23436\\4010348627.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_missing[col] = y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature 'thal' has been imputed with 72.41 accuracy\n",
      "\n",
      "The feature 'ca' has been imputed with 66.13 accuracy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\P70088666\\AppData\\Local\\Temp\\ipykernel_23436\\4010348627.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_missing[col] = y_pred\n",
      "C:\\Users\\P70088666\\AppData\\Local\\Temp\\ipykernel_23436\\4010348627.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_with_missing[col] = y_pred\n"
     ]
    }
   ],
   "source": [
    "for col in categ_cols: \n",
    "    df_with_missing = df_procesed[df_procesed[col].isna()]\n",
    "    # dropna removes all rows with missing values\n",
    "#     df_without_missing = df.dropna()\n",
    "    df_without_missing = df_procesed[df_procesed[col].notna()]\n",
    "    \n",
    "    # split the data into X and y and we will only take the columns with no missing values\n",
    "    X = df_without_missing.drop([col], axis=1)\n",
    "    y = df_without_missing[col]\n",
    "\n",
    "    # split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=60)\n",
    "\n",
    "    # Random Forest Imputation\n",
    "    rf_model = LGBMClassifier(verbose = -1,learning_rate = 0.023021779601797816, num_leaves = 149, subsample = 0.6929884706542179, colsample_bytree = 0.8635308367372507, min_data_in_leaf = 47, random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the model\n",
    "    y_preds = rf_model.predict(X_test)\n",
    "\n",
    "    y_pred = rf_model.predict(df_with_missing.drop([col], axis=1))\n",
    "    \n",
    "    acc_score = accuracy_score(y_test, y_preds)\n",
    "    \n",
    "    print(\"The feature '\"+ col+ \"' has been imputed with\", round((acc_score * 100), 2), \"accuracy\\n\")\n",
    "    df_with_missing[col] = y_pred\n",
    "    \n",
    "    df_procesed = pd.concat([df_with_missing, df_without_missing], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesed = df_procesed[df_procesed['trestbps'] >50]\n",
    "df_procesed = df_procesed[(df_procesed['chol'] > 30) & (df_procesed['chol']<300)]\n",
    "df_procesed.drop_duplicates(inplace=True) \n",
    "\n",
    "df['num_bins']=pd.cut(df['num'], bins=[0,1,2,3,4], include_lowest=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outlier = df_procesed[(df_procesed['chol'] < 30)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# apply KNN Imputer to the entire dataset\n",
    "df_procesed = pd.DataFrame(imputer.fit_transform(df_procesed), columns=df_procesed.columns)\n",
    "\n",
    "# show the first rows of the transformed dataset\n",
    "df_procesed.head()\n",
    "# Here I am also creating an outlier dataset to examine causal inference \n",
    "df_procesed = df_procesed[(df_procesed['trestbps'] > 50)]\n",
    "df_outlier = df_procesed[(df_procesed['trestbps'] < 50)]\n",
    "df_procesed = df_procesed[(df_procesed['chol'] > 30)]\n",
    "df_outlier = df_procesed[(df_procesed['chol'] > 30)]\n",
    "\n",
    "from sklearn.preprocessing import QuantileTransformer \n",
    "scaler = QuantileTransformer(output_distribution='normal')\n",
    "numerical_features = [ 'trestbps', 'chol', 'thalch', 'oldpeak']\n",
    "#df_procesed[numerical_features] = scaler.fit_transform(df_procesed[numerical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesed.to_csv('heart_disease_uci_processed.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan_data.csv')\n",
    "columns_to_encode = ['person_gender', 'person_education', 'person_home_ownership', 'loan_intent', 'previous_loan_defaults_on_file']\n",
    "num_columns = [\n",
    "    'person_income', \n",
    "    'loan_amnt', \n",
    "    'loan_int_rate', \n",
    "    'loan_percent_income', \n",
    "    'cb_person_cred_hist_length', \n",
    "    'credit_score'\n",
    "]\n",
    "encoder = LabelEncoder()\n",
    "scaler = StandardScaler()\n",
    "df_procesed = df.copy()\n",
    "for column in columns_to_encode:\n",
    "    df_procesed[column] = encoder.fit_transform(df_procesed[column])\n",
    "\n",
    "df_procesed.to_csv('loan_data_processed.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_gender</th>\n",
       "      <th>person_education</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>previous_loan_defaults_on_file</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>71948.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>16.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>561</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12438.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12.87</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>635</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>79753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15.23</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>675</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>66135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14.27</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>586</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44995</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47971.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15.66</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44996</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65800.0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>14.07</td>\n",
       "      <td>0.14</td>\n",
       "      <td>11.0</td>\n",
       "      <td>621</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44997</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56942.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2771.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10.0</td>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44998</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33164.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.23</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>604</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44999</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>51609.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6665.0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_age  person_gender  person_education  person_income  \\\n",
       "0            22.0              0                 4        71948.0   \n",
       "1            21.0              0                 3        12282.0   \n",
       "2            25.0              0                 3        12438.0   \n",
       "3            23.0              0                 1        79753.0   \n",
       "4            24.0              1                 4        66135.0   \n",
       "...           ...            ...               ...            ...   \n",
       "44995        27.0              1                 0        47971.0   \n",
       "44996        37.0              0                 0        65800.0   \n",
       "44997        33.0              1                 0        56942.0   \n",
       "44998        29.0              1                 1        33164.0   \n",
       "44999        24.0              1                 3        51609.0   \n",
       "\n",
       "       person_emp_exp  person_home_ownership  loan_amnt  loan_intent  \\\n",
       "0                   0                      3    35000.0            4   \n",
       "1                   0                      2     1000.0            1   \n",
       "2                   3                      0     5500.0            3   \n",
       "3                   0                      3    35000.0            3   \n",
       "4                   1                      3    35000.0            3   \n",
       "...               ...                    ...        ...          ...   \n",
       "44995               6                      3    15000.0            3   \n",
       "44996              17                      3     9000.0            2   \n",
       "44997               7                      3     2771.0            0   \n",
       "44998               4                      3    12000.0            1   \n",
       "44999               1                      3     6665.0            0   \n",
       "\n",
       "       loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \\\n",
       "0              16.02                 0.49                         3.0   \n",
       "1              11.14                 0.08                         2.0   \n",
       "2              12.87                 0.44                         3.0   \n",
       "3              15.23                 0.44                         2.0   \n",
       "4              14.27                 0.53                         4.0   \n",
       "...              ...                  ...                         ...   \n",
       "44995          15.66                 0.31                         3.0   \n",
       "44996          14.07                 0.14                        11.0   \n",
       "44997          10.02                 0.05                        10.0   \n",
       "44998          13.23                 0.36                         6.0   \n",
       "44999          17.05                 0.13                         3.0   \n",
       "\n",
       "       credit_score  previous_loan_defaults_on_file  loan_status  \n",
       "0               561                               0            1  \n",
       "1               504                               1            0  \n",
       "2               635                               0            1  \n",
       "3               675                               0            1  \n",
       "4               586                               0            1  \n",
       "...             ...                             ...          ...  \n",
       "44995           645                               0            1  \n",
       "44996           621                               0            1  \n",
       "44997           668                               0            1  \n",
       "44998           604                               0            1  \n",
       "44999           628                               0            1  \n",
       "\n",
       "[45000 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_procesed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
